<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!--suppress CheckImageSize -->
<html xmlns="http://www.w3.org/1999/xhtml">

  <head>

    <script src="js/head.js?prefix="></script>
    <meta name="description" content="AdvCL">

    <title>AdvCL</title>
    <link rel="stylesheet" href="css/font.css">
    <link rel="stylesheet" href="css/main.css">

  </head>

  <body>

    <div class="outercontainer">
      <div class="container">

        <div class="content project_title">
          <h1>When Does Contrastive Learning Preserve Adversarial Robustness from Pretraining to Finetuning?</h1>
        </div>

        <div class="content project_headline">
          <div class="img" style="text-align:center">
            <img class="img_responsive" src="images/advcl_model.png" alt="AdvCL" style="margin:auto;max-width:80%"/>
          </div>
          <div class="text">
            <p>Figure 1: The overall pipeline of AdvCL. It mainly has two ingredients: robustness-aware view selection (orange box) and pseudo-supervision stimulus generation (blue box). The view selection mechanism is advanced by high frequency components, and the supervision stimulus is created by generating pseudo labels for each image through ClusterFit. The pseudo label (in yellow color) can be created in an offline manner and will not increase the computation overhead.
            </p>
          </div>
        </div>
        <!--<div class="content project_headline">-->
          <!--<div class="img" style="text-align:center">-->
            <!--<img class="img_responsive" src="images/results.jpg" alt="AdvCL Result" style="margin:auto;max-width:80%"/>-->
          <!--</div>-->
          <!--<div class="text">-->
            <!--<p>Figure 2: AdvCL result</p>-->
          <!--</div>-->
        <!--</div>-->

        <div class="content">

        <div class="content">
          <p class="text">
            <h3>Abstract</h3>
          <p>Contrastive learning (CL) can learn generalizable feature representations and achieve state-of-the-art performance of downstream tasks by finetuning a linear classifier on top of it. However, as adversarial robustness becomes vital in image classification, it remains unclear whether or not CL is able to preserve robustness to downstream tasks. The main challenge is that in the
            'self-supervised pretraining + supervised finetuning' paradigm, adversarial robustness is easily forgotten due to a learning task mismatch from pretraining to finetuning. We call such challenge 'cross-task robustness transferability'.</p>
          <p>To address the above problem, in this paper we revisit and advance CL principles through the lens of robustness enhancement. We show that (1) the design of contrastive views matters: High-frequency components of images are beneficial to improving model robustness; (2) Augmenting CL with pseudo-supervision stimulus (e.g., resorting to feature clustering) helps preserve robustness without forgetting. Equipped with our new designs, we propose AdvCL, a novel adversarial contrastive pretraining framework. We show that AdvCL is able to enhance cross-task robustness transferability without loss of model accuracy and finetuning efficiency. With a thorough experimental study, we demonstrate that AdvCL outperforms the state-of-the-art self-supervised robust learning methods across multiple datasets (CIFAR-10, CIFAR-100 and STL-10) and finetuning schemes (linear evaluation and full model finetuning).
            </p>
          </div>
        </div>

        <!--<div class="content">-->
          <!--<div class="text">-->
            <!--<h3>Spotlight Video</h3>-->
          <!--</div>-->
          <!--<div class="project_headline">-->
            <!--<iframe width="720" height="405" src="https://www.youtube.com" frameborder="0" allowfullscreen></iframe>-->
            <!--<p>If you cannot access YouTube, please <a href="videos/">download our video here</a>.</p>-->
          <!--</div>-->
        <!--</div>-->

        <div class="content">
          <!-- <div class="text"> -->
            <h3>Publication</h3>
            <ul>
              <li>
              <div class="title"><a name="AdvCL_Neurips">When Does Contrastive Learning Preserve Adversarial Robustness from Pretraining to Finetuning?</a></div>
                <div class="authors">
                  <a href="http://lijiefan.me">Lijie Fan</a>,
                  <a href="https://lsjxjtu.github.io/">Sijia Liu</a>,
                  <a href="https://sites.google.com/site/pinyuchenpage">Pin-Yu Chen</a>,
                  Gaoyuan Zhang, and
                  <a href="https://people.csail.mit.edu/ganchuang/">Chuang Gan</a>
                </div>
                <div>
                  <span class="venue">NeurIPS 2021 </span>
                  <span class="tag"><a href="papers/AdvCL_Neurips.pdf">Paper</a></span>
                  <span class="tag"><a href="https://arxiv.org/abs/2111.01124">arXiv</a></span>
                  <span class="tag"><a href="bibtex/AdvCL_neurips.bib">BibTeX</a></span>
                  <span class="tag"><a href="https://github.com/LijieFan/AdvCL">code</a></span>
                </div>
              </li>
            </ul>
          <!-- </div> -->
        </div>

        <!--<div class="content">-->
          <!--<div class="text">-->
            <!--<h3>Downloads</h3>-->
			      <!--<ul class="download">-->
              <!--<li><a href="">Pretrained models and code for AdvCL</a></li>-->
			      <!--</ul>-->
          <!--</div>-->
        <!--</div>-->

      </div>
    </div>

  </body>

</html>
